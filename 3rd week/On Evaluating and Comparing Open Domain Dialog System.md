## On Evaluating and Comparing Open Domain Dialog System
## 摘要
- Alexa prize为学术界提供了利用数百万用户使用的实时系统进行研究的独特机会
- 提出了一种综合评估策略，该评估策略具有多个指标，旨在通过选择与人工评价相关的指标来降低主观性，这些指标可以用作人类判断的合理替代
- 提供一种机制来统一选择表现最佳的闲聊系统的指标，这一机制也已在整个Alexa奖竞赛中得到应用
- 使用的数据具有数百万次的对话和来自用户的数十万个评分

## 简介
图灵测试是不合理的：
- 不可比较的元素：鉴于AI可以处理的知识量很大，因此没有理由表明人类和AI应该产生相似的回复。 
闲聊机器人的互动方式可能与人不同，但仍可能是优秀的对话者
- 鼓励产生合理但信息含量低的内容：如果主要度量回复的合理性，则很容易选择退出更具挑战性的响应生成和对话管理领域。 
在生成合理的回复的同时，能够获取有趣且相关的内容非常重要。
- 人类在通过写作和说话对话时表现是不一样的
- 在Alexa奖的背景下，模拟社交对话的特定目标以及缺乏对“聊天机器人”的标准含义的普遍认同，导致使用“社交机器人”一词来描述比赛的对话主体，
这就是 一个能够与社交对话中常见的开放域对话主题进行交互的聊天机器人
- 为了评估Alexa奖社交机器人，我们开发了一个基于参与度，领域覆盖范围，连贯性，主题多样性和对话深度的框架。 
我们通过针对数十万个对话进行验证，证明了这些指标与人类判断具有很好的一致性。

## Alexa prize
参加Alexa奖的大学团队的任务是建立能够在政治，体育，娱乐，时尚和科技等领域就热门话题和新闻事件进行社交对话的机器人
对话设置的一个独特方面是，为对话提供评分的用户是参与对话本身的人。 在大多数非目标对话的现有工作中，评估是由独立的评估者离线进行的。

## 评价指标
