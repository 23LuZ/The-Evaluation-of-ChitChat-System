## On Evaluating and Comparing Open Domain Dialog System
## 摘要
- Alexa prize为学术界提供了利用数百万用户使用的实时系统进行研究的独特机会
- 提出了一种综合评估策略，该评估策略具有多个指标，旨在通过选择与人工评价相关的指标来降低主观性，这些指标可以用作人类判断的合理替代
- 提供一种机制来统一选择表现最佳的闲聊系统的指标，这一机制也已在整个Alexa奖竞赛中得到应用
- 使用的数据具有数百万次的对话和来自用户的数十万个评分

## 简介
图灵测试是不合理的：
- 不可比较的元素：鉴于AI可以处理的知识量很大，因此没有理由表明人类和AI应该产生相似的回复。 
闲聊机器人的互动方式可能与人不同，但仍可能是优秀的对话者
- 鼓励产生合理但信息含量低的内容：如果主要度量回复的合理性，则很容易选择退出更具挑战性的响应生成和对话管理领域。 
在生成合理的回复的同时，能够获取有趣且相关的内容非常重要。
- 人类在通过写作和说话对话时表现是不一样的
- 在Alexa奖的背景下，模拟社交对话的特定目标以及缺乏对“聊天机器人”的标准含义的普遍认同，导致使用“社交机器人”一词来描述比赛的对话主体，
这就是 一个能够与社交对话中常见的开放域对话主题进行交互的聊天机器人
- 为了评估Alexa奖社交机器人，我们开发了一个基于参与度，领域覆盖范围，连贯性，主题多样性和对话深度的框架。 
我们通过针对数十万个对话进行验证，证明了这些指标与人类判断具有很好的一致性。

## Alexa prize
参加Alexa奖的大学团队的任务是建立能够在政治，体育，娱乐，时尚和科技等领域就热门话题和新闻事件进行社交对话的机器人
对话设置的一个独特方面是，为对话提供评分的用户是参与对话本身的人。 在大多数非目标对话的现有工作中，评估是由独立的评估者离线进行的。

## 评价指标
提出了一组指标，可以对其进行计算以客观地评估和比较闲聊模型
- 主题提取模型  
DAN
- 对话用户体验 Conversational User Experiencce(CUX)  
与社交机器人的对话跟与人的对话是不同，造成这种差异的潜在原因有：  
    - 期待 Expectation：人们与社交机器人聊天的目的是不同的，有的期待正确的回复，有的只是想要一个可以倾听的朋友。
    - 行为和情感 Behavior and Sentiment：不会担心影响与机器人的关系，所以会和机器人有不同程度的表达的自由
    - 信任 Trust：与人类相比，和社交机器人的对话的安全程度的观点是不同的。当用户在系统中建立信任时，他们可能开始通过意见请求，表明需要陪伴的对话请求等方式来表示对社交机器人的更高信任。
    - 视觉提示和身体状况 Visual Cues and Physicality：缺少视觉提示和身体信号（例如韵律，肢体语言）可能会影响对话的内容和方向。

- 参与度 Engagement  
参与度是对话中有趣程度的衡量标准。使用轮数（number of dialogue-turns）和总对话时长（total conversation duration）来表明用户在对话中的参与度。
当用户倾向于对社交机器人的参与度和趣味性进行详细审查时，他们对对话的评分可能会低于对总体体验的评分。
- 连贯性  
连贯的回复表示对用户问题的可理解且相关的回复。为了获得连贯性，注释了数十万个随机选择的对话，包括不正确，无关或不适当的回复。 使用注释，计算了每个社交机器人的回复错误率（RER），定义为：RER= Number of incoherent responses/Total number of utterance
- 域覆盖 Domain Coverage
域特定的对话代理可能更类似于任务型对话系统，其输出响应空间是有界的。 能够在多个域上进行交互的代理可以被认为与人们的期望更加一致。  
确定每个社交机器人的所有对话中用户话语和回复的主题。然后计算跨域的熵，较高的熵代表社交机器人的对话主题覆盖多个域，而较低的熵表示社交机器人只针对一些主题或域。  
计算了五个领域（体育，政治，娱乐，技术，时尚）的评分的标准差（STD）。 识别社交机器人的评分分布是否偏向特定领域或在所有领域的表现均相同。  
为了进行评价，我们最大化熵，同时最小化跨多个域的熵的标准偏差。 高熵确保社交机器人谈论各种话题，而低标准偏差则使我们确信该度量标准是一个有正确的度量标准。 为了结合熵和社交机器人跨域评分的标准偏差，我们将反向变异系数（R-COV）视为评价域覆盖率的综合指标。 R-COV是通过获取每个社交机器人对话中基于平均域分布的熵和相应标准偏差的比值获得的
- 对话深度 Conversational Depth
人类对话通常会深入某个主题，能够深入讨论某个主题的机器人会更自然。为了评价对话深度，使用主题模型识别每个话语的主题，然后通过计算讨论相同主题的连续轮数的平均值，平均值越大说明对话越深入。
- 主题多样性/对话广度  
广度取决于粗略的主题领域（例如政治，体育，音乐等）以及细粒度的主题关键字（例如，奥巴马，费德勒，约翰·列侬等）。使用主题词汇表的大小评价主题多样性，还测量社交机器人的每个主题的分布，使用它来衡量社交机器人的主题亲和力。
- 评价指标的统一 Unification of Evaluation Metrics  
社交机器人可以在多个维度上进行评价，机器人可能在某个方面表现较好，而在另一方面表现较差。对于Alexa Prize,使用基于对话质量的排名评价社交机器人。  
共有三种策略：
    - 堆栈排名 stack ranking  
    根据单个指标对机器人进行排名，并使用各个指标的总和生成分数。 如果所有指标并非同等重要，则可以采用加权堆栈排名方法。但是，如果度量标准值中的误差条指示差异不明显，则堆栈排名可能无法提供最合适的解决方案。
    - 赢家圈 winner circle
    将人类评分最高的两个社交机器人作为基准，其他社交机器人在每个指标上都与基准机器人进行比较，若表现差在误差条内那么得分为1，否则为0.加起来作为总分然后排名。
    - 置信带 confidence bands
    针对每一个指标，将得分最高的两个社交机器人作为基准，其他社交机器人与基准机器人进行比较，若表现差在误差条内那么得分为1，否则为0.
- 自动用户评分  
使用Alexa用户的评分作为参考值，使用话语级别和对话级别的特征构建一个能够自动评分的模型。所用到的特征有：n-gram of user-bot turns,用户话语和社交机器人回复之间相同的单词，对话持续时间，轮数和平均回复时间。使用Gradient Boosted Tree (GBDT)和Hierarchical LSTM (HLSTM)训练模型。

## 结论
- 统一指标与用户评分之间的强相关性表明，可以使用统一指标作为用户评分的代理。  
- 未来，使用更多的数据、结合更多的特征训练模型  
- 用户可能会给对话打5颗星，因为他/她认为社交机器人很幽默，而另一个用户可能觉得它很无聊。 用户可能有自己的标准来评估社交机器人。 因此，作为未来工作的一部分，希望使用用户级别的特征来训练模型。
- 测试以前在较小数据集上完成的一些指标的可伸缩性，以查看它们是否可以合并到流程中
- 训练基于常用用户评分来预测CUX的模型
- 连贯性、参与度和对话用户体验指标都有人参与，利用收集到的数据，可以有监督的训练模型自动预测这些指标。Lowe等人提出的模型机器变体可以进一步扩展来获得这些指标。


