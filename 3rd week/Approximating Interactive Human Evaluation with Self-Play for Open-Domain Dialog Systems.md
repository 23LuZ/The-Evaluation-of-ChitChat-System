## Approximating Interactive Human Evaluation with Self-Play for Open-Domain Dialog Systems
### 摘要
- 当前的评价方法主要是对静态对话质量的评价，无法实现在现实的交互环境中评价对话质量
- 探索交互式人工评价，提出了一个新奇的，与模型无关，与数据无关的方法来近似模拟交互式人工评价
- 提出self-play场景：闲聊机器人与自己进行对话，利用对话数据，计算多种评价指标的组合
- 实验结果证明提出的评价指标比任何自动化评价指标都能更好地捕获到对话模型的人工评价质量

### 简介
- 静态评价 static evaluation：训练对话模型的数据集被分为训练集、验证集和测试集，测试集中的问题作为对话模型的输入，得到生成回复。然后由人来
判断生成回复的质量。但是，静态评价不能捕获到对话模型的一些常见缺陷如无法保持一致的个性、回复缺乏多样性、回复存在重复等。
- 对话是一个过程，多轮交互式人工评价对评价这个过程是很重要 
- 多轮交互式评价是开放的，允许用户说任何想说的话来主导整个对话
- 相比于静态评价，多轮交互式评价是对泛化的最终检验
- 多轮交互式评价未发展的原因可能是收集人工数据的难度较大，费时费力
- 提出对话self-play框架来模拟多轮交互式评价
- 提出评价情感、语义和用户参与度的评价指标，根据这些指标，拟合函数可预测人类对对话质量的评价结果
- 该函数通过self-play预测闲聊机器人的质量:对于预设的固定轮数，闲聊机器人生成的回复作为下一轮的输入。评价指标针对这些对话数据进行评价，然后拟合函数
预测闲聊机器人的质量
- 实验结果证明，预测的机器人质量分数与人工评价具有很高的相关性
- 为了展示交互式评价和self-paly评价的相关性，比较不同层次结构的对话模型：HRED,VHRED,VHCR
- 情感和语义是生成高质量的对话的重要因素，使用模型蒸馏正则化了层次结构的顶层，以确保对这些信息进行编码
- 三个主要的贡献
    - 多轮交互式评价对闲聊机器人的评价是很必要的
    - 提出self-play框架，以估算综合质量得分，这些估算值与通过互动式人工评价获得的质量得分高度相关，比最新的自动化指标更强
    - 提出了一种新的利用知识蒸馏来正则化seq2seq模型的方法
   
### 相关工作
- 对话中的交互式评价方法主要限于展示比赛结果
- 即使是为了保持一致个性而提出的模型也没有在交互式环境下评价

### 用于情感和语义正则化的知识蒸馏
- 情绪和推断正则化（EI）  
这些模型的分层设计是出于希望跟踪对话的高层，变化缓慢的方面例如主题或语气，但尚不清楚网络是否能够在没有其他结构或信息的情况下对这些方面进行建模。
因此，提出对层次结构的最高层（上下文RNN）进行正则化，以强制其对话语的情感和语义进行编码。 为此，利用在大型Twitter语料库上训练的最先进的情感检测模型，
以及最近提出的句子向量模型来预测句子的含义（即蕴涵，矛盾），并将其提炼到上下文RNN中。

### 交互式评价方法
- 传统评价方法  
    - 自动评价方法 基于词向量的评价方法 困惑度 KL散度
    - 常规静态人工评价方法：从五个维度进行评价：质量，流利度，多样性，偶然性和同理心
- 交互式人工评价方法  
评价者在与机器人进行至少3轮互动后，对机器人的质量，流畅性，多样性，相关性和同情心进行了评分
- 新的评价方法和self-play  
提出这些评价指标的组合M_H
     - 情感评价方法：在Twitter数据集上训练的效果最好的情感分类器，其输出为64维情感向量，每一维代表一个最常用的表情。
     为了估算用户查询和生成回复之间的**情感连贯性**，计算它们的情感向量之间的余弦相似度。
     在64个表情符号上定义了一组权重，并计算了情感向量的加权总和，以得出情感分数，对于正面情绪而言，该分数较高，对于负面情绪而言，该分数较低。
     将**情感转变**定义为机器人回复前后用户的情感变化。**情感最小-最大值**定义为用户话语中情绪最小值和最大值之间的变化斜率。
     统计‘ha’的数量作为笑的代表。  
     这些指标的组合提供了对话中情绪轨迹的快照，并量化了机器人是否能够在用户中引起积极情绪
     - 语义评价方法：效果最好的句子向量模型Infersent，可以将用户话语和生成回复编码为4096维向量。
     Infersent模型的训练方法为区分两个句子是支持，矛盾还是中立的关系。 
     通过计算用户查询向量与生成回复向量之间的余弦相似度来估算语义相似度。
     - 用户参与度：提问是一项重要的主动聆听技巧，定义问题分数来量化机器人是否使用疑问词和/或问号。 
     还引入了#Words作为用户参与度的代理，它可以统计用户响应中的单词数。
     - 混合指标 M_H: 使用线性回归结合前面提到的评价指标，并优化与交互式人工评价的相关性系数。  
     - self-play 每个对话模型进行100个自我对话，每个对话为10轮，计算M_H
     
### 实验
- 数据集 Cornell 数据集 Reddit数据集
- 基于词向量的评价指标在保持人类评价的顺序方面显示出更大的希望，但与人类评价的相关性很弱。
- 静态的人工评价表明，由于获胜判断次数更多，EI正则化是有效的，由于置信区间大和平局比例高，结果嘈杂且难以解释
- 
### 结论
- 开放域对话生成中的主要障碍是目标函数的优化，该目标函数与人类对对话质量的判断不完全匹配。

     

